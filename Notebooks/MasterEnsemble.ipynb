{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "MasterEnsemble.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HxSQ0GBTOx8i"
      },
      "source": [
        "import os\n",
        "import tweepy as tw\n",
        "import pandas as pd\n",
        "import csv\n",
        "import pandas as pd\n",
        "import glob\n",
        "from nltk.corpus import stopwords\n",
        "#from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "import numpy as np\n",
        "import re\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import tensorflow.keras as keras\n",
        "import tensorflow.keras.layers as layers\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras.models\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.utils import to_categorical\n",
        "from keras import backend as K\n",
        "from sklearn.metrics import accuracy_score\n",
        "from keras.models import load_model\n",
        "from keras.utils import to_categorical\n",
        "from keras.utils import plot_model\n",
        "from keras.models import Model\n",
        "from keras.layers import Input\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.layers import Dropout\n",
        "from keras.layers.merge import concatenate\n",
        "from numpy import argmax"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFGsFBF0PIN3",
        "outputId": "8c143313-8cbc-4698-b590-90578ec79661"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H1GQXlPMOx8k"
      },
      "source": [
        "extension = 'csv'\n",
        "all_filenames = [i for i in glob.glob('/content/drive/MyDrive/twit/train/*.{}'.format(extension))]\n",
        "\n",
        "#combine all files in the list\n",
        "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "#export to csv\n",
        "combined_csv.to_csv( \"aggregate.csv\", index=False, encoding='utf-8-sig')"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "Zl2_zX5UOx8n",
        "outputId": "d8f8526d-dddf-4e53-88ec-bde2cc019c02"
      },
      "source": [
        "train = pd.read_csv('/content/drive/MyDrive/twit/train/aggregate.csv')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.289490e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.289770e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>@Microsoft how about you make a system that do...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.290230e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>I may be ignorant on this issue but... should ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.291790e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>Thanks to @microsoft, I just may be switching ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.291860e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>If I make a game as a #windows10 Universal App...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Column1   Column2                                            Column3\n",
              "0  6.289490e+17  negative  dear @Microsoft the newOoffice for Mac is grea...\n",
              "1  6.289770e+17  negative  @Microsoft how about you make a system that do...\n",
              "2  6.290230e+17  negative  I may be ignorant on this issue but... should ...\n",
              "3  6.291790e+17  negative  Thanks to @microsoft, I just may be switching ...\n",
              "4  6.291860e+17   neutral  If I make a game as a #windows10 Universal App..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHMAxp3_Gjea"
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\r\n",
        "  r = re.findall(pattern, input_txt)\r\n",
        "  for i in r:\r\n",
        "    input_txt = re.sub(i, '', input_txt)        \r\n",
        "  return input_txt\r\n",
        "\r\n",
        "def clean_tweets(frame, column_name, remove_stop_words=True, lower_case=True, remove_special=True):\r\n",
        "  frame = frame.drop_duplicates().reset_index(drop=True) #remove duplicate rows\r\n",
        "  frame['Tweet_Clean_Text'] = np.vectorize(remove_pattern)(frame[column_name], \"RT @[\\w]*:\") #remove twitter return handle\r\n",
        "  frame.Tweet_Clean_Text = np.vectorize(remove_pattern)(frame['Tweet_Clean_Text'], \"@[\\w]*\") #remove twitter handle\r\n",
        "  frame.Tweet_Clean_Text = np.vectorize(remove_pattern)(frame['Tweet_Clean_Text'], \"https?://[A-Za-z0-9./]*\") #remove URLs\r\n",
        "\r\n",
        "  if remove_special:\r\n",
        "    frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.str.replace(\"[^a-zA-Z#]\", \" \") #remove special characters except for #\r\n",
        "  frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.replace('\\s+', ' ', regex=True) #remove extra spaces in between words\r\n",
        "  if lower_case:\r\n",
        "    frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.apply(lambda x: x.lower())\r\n",
        "  if remove_stop_words:\r\n",
        "    frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.apply(lambda x: ' '.join([word for word in x.split() if word not in stopwords.words('english')])) #remove stop words\r\n",
        "\r\n",
        "  return frame"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "id": "XHk6IGNMOx8p",
        "outputId": "ad665f02-3e00-47d5-8734-9c78cd9034e0"
      },
      "source": [
        "train_set = clean_tweets(train, 'Column3', remove_stop_words=False, remove_special=False)\r\n",
        "train_set.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Tweet_Clean_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.289490e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
              "      <td>dear the newooffice for mac is great and all, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.289770e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>@Microsoft how about you make a system that do...</td>\n",
              "      <td>how about you make a system that doesn't eat ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.290230e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>I may be ignorant on this issue but... should ...</td>\n",
              "      <td>i may be ignorant on this issue but... should ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.291790e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>Thanks to @microsoft, I just may be switching ...</td>\n",
              "      <td>thanks to , i just may be switching over to .</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.291860e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>If I make a game as a #windows10 Universal App...</td>\n",
              "      <td>if i make a game as a #windows10 universal app...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Column1  ...                                   Tweet_Clean_Text\n",
              "0  6.289490e+17  ...  dear the newooffice for mac is great and all, ...\n",
              "1  6.289770e+17  ...   how about you make a system that doesn't eat ...\n",
              "2  6.290230e+17  ...  i may be ignorant on this issue but... should ...\n",
              "3  6.291790e+17  ...      thanks to , i just may be switching over to .\n",
              "4  6.291860e+17  ...  if i make a game as a #windows10 universal app...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "ueTzZRHxOx8t",
        "outputId": "e7342308-6768-4804-ed19-6e0d83d97fd6"
      },
      "source": [
        "train_set[\"Sentiment_Value\"] = train_set[\"Column2\"].map({\"neutral\": 0, \"positive\": 1, \"negative\": 2})\n",
        "label = to_categorical(train_set[\"Sentiment_Value\"], 3)\n",
        "train_set"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Tweet_Clean_Text</th>\n",
              "      <th>Sentiment_Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>6.289490e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>dear @Microsoft the newOoffice for Mac is grea...</td>\n",
              "      <td>dear the newooffice for mac is great and all, ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6.289770e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>@Microsoft how about you make a system that do...</td>\n",
              "      <td>how about you make a system that doesn't eat ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.290230e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>I may be ignorant on this issue but... should ...</td>\n",
              "      <td>i may be ignorant on this issue but... should ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>6.291790e+17</td>\n",
              "      <td>negative</td>\n",
              "      <td>Thanks to @microsoft, I just may be switching ...</td>\n",
              "      <td>thanks to , i just may be switching over to .</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>6.291860e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>If I make a game as a #windows10 Universal App...</td>\n",
              "      <td>if i make a game as a #windows10 universal app...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114213</th>\n",
              "      <td>2.103780e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>It's a Wednesday girls night out as '90's band...</td>\n",
              "      <td>it's a wednesday girls night out as '90's band...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114214</th>\n",
              "      <td>2.451780e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>night college course sorted, just have to enro...</td>\n",
              "      <td>night college course sorted, just have to enro...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114215</th>\n",
              "      <td>2.592810e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>For the 1st time in 30 years. For your splendi...</td>\n",
              "      <td>for the 1st time in 30 years. for your splendi...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114216</th>\n",
              "      <td>2.011140e+17</td>\n",
              "      <td>positive</td>\n",
              "      <td>NURSES DAY - 12 MAY 2012. Nursing: The heart b...</td>\n",
              "      <td>nurses day - 12 may 2012. nursing: the heart b...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114217</th>\n",
              "      <td>2.379990e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>We have 15 minutes left until the 2nd episode ...</td>\n",
              "      <td>we have 15 minutes left until the 2nd episode ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114218 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Column1  ... Sentiment_Value\n",
              "0       6.289490e+17  ...               2\n",
              "1       6.289770e+17  ...               2\n",
              "2       6.290230e+17  ...               2\n",
              "3       6.291790e+17  ...               2\n",
              "4       6.291860e+17  ...               0\n",
              "...              ...  ...             ...\n",
              "114213  2.103780e+17  ...               0\n",
              "114214  2.451780e+17  ...               1\n",
              "114215  2.592810e+17  ...               1\n",
              "114216  2.011140e+17  ...               1\n",
              "114217  2.379990e+17  ...               0\n",
              "\n",
              "[114218 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYnFABQ1Gd7o",
        "outputId": "f57cf6ab-a01c-40bc-fce3-323b5871b0aa"
      },
      "source": [
        "train['l'] = train_set['Tweet_Clean_Text'].apply(lambda x: len(str(x).split(' ')))\r\n",
        "print(\"mean length of sentence: \" + str(train.l.mean()))\r\n",
        "print(\"max length of sentence: \" + str(train.l.max()))\r\n",
        "print(\"std dev length of sentence: \" + str(train.l.std()))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean length of sentence: 16.71109632457231\n",
            "max length of sentence: 40.0\n",
            "std dev length of sentence: 6.599111305083614\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NRyal2-9GvfW"
      },
      "source": [
        "sequence_length = train.l.max() #using the maximum length "
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0BrfvQmpOx8v",
        "outputId": "e31a10fd-8f77-420c-9a4f-3df1f1b31f55"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(train_set['Tweet_Clean_Text'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(train_set['Tweet_Clean_Text'].values)\n",
        "X = pad_sequences(X, maxlen=int(sequence_length), padding='post')\n",
        "X\n",
        "\n",
        "print(\"training size \" + str(len(x_train)))\n",
        "\n",
        "voc_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocab size: \", voc_size)\n",
        "print(\"Input shape: \", X.shape)\n",
        "print(\"Y_shape: \" , label.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training size 102796\n",
            "Vocab size:  73456\n",
            "Input shape:  (114218, 40)\n",
            "Y_shape:  (114218, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Cb6FfSOx8w"
      },
      "source": [
        "#FINAL DATASETS (Please note case sensitivity)- TRAINING: (X_train,Y_train)  VALIDATION: (X_val, Y_val)  TEST: (X_test, Y_test)\r\n",
        "\r\n",
        "x_train, X_test, y_train, Y_test = train_test_split(X, label, test_size=0.10, shuffle=False, random_state=10)\r\n",
        "\r\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size=0.15, shuffle=True, random_state=10)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rsnkTWO-Ox8w"
      },
      "source": [
        "def recall_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    recall_score.__name__ = 'recall'\n",
        "    return recall\n",
        "\n",
        "def precision_score(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    precision_score.__name__ = 'precision'\n",
        "    return precision\n",
        "\n",
        "\n",
        "def f1_metrics(y_true, y_pred):\n",
        "    precision = precision_score(y_true, y_pred)\n",
        "    recall = recall_score(y_true, y_pred)\n",
        "    f1_metrics.__name__ = 'f1_metrics'\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
        "\n",
        "metrics = [\n",
        "           keras.metrics.CategoricalAccuracy(),\n",
        "           keras.metrics.Precision(name='precision'),\n",
        "           keras.metrics.Recall(name='recall'),\n",
        "           f1_metrics,\n",
        "]"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "btoXteOMOx8y",
        "outputId": "18295e98-dbe3-4e3d-a153-72e07fa435da"
      },
      "source": [
        "# stacked generalization with neural net meta model on blobs dataset\n",
        "\n",
        "# load models from file\n",
        "def load_all_models(model_names):\n",
        "\tall_models = list()\n",
        "\tfor model_name in model_names:\n",
        "\t\t# define filename for this ensemble\n",
        "\t\tfilename = '/content/drive/MyDrive/twit/train/models/' + model_name\n",
        "\t\t# load model from file\n",
        "\t\tmodel = load_model(filename,custom_objects={'f1_metrics':f1_metrics,'precision':precision_score,'recall':recall_score})\n",
        "\t\t# add to list of members\n",
        "\t\tall_models.append(model)\n",
        "\t\tprint('>loaded %s' % filename)\n",
        "\treturn all_models\n",
        "\n",
        "# load all models\n",
        "members = ['LSTM200.h5', 'LSTM150.h5', 'LSTM120.h5', 'LSTM250.h5', 'LSTM60.h5']\n",
        "members = load_all_models(members)\n",
        "print('Loaded %d models' % len(members))\n",
        "\n",
        "train_predictions = []\n",
        "val_predictions = []\n",
        "test_predictions = []\n",
        "\n",
        "for model in members:\n",
        "  train_predictions.append(model.predict([X_train], batch_size=1024))\n",
        "  val_predictions.append(model.predict([X_val], batch_size=1024))\n",
        "  test_predictions.append(model.predict([X_test], batch_size=1024))\n",
        "  print('Predicted one thing')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/twit/train/models/LSTM200.h5\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_6 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/twit/train/models/LSTM150.h5\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_7 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/twit/train/models/LSTM120.h5\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_8 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/twit/train/models/LSTM250.h5\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_9 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            ">loaded /content/drive/MyDrive/twit/train/models/LSTM60.h5\n",
            "Loaded 5 models\n",
            "Predicted one thing\n",
            "Predicted one thing\n",
            "Predicted one thing\n",
            "Predicted one thing\n",
            "Predicted one thing\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPWOodkLl7hj"
      },
      "source": [
        "from keras.layers import BatchNormalization\r\n",
        "def ensemble(predictions, targets, xval, yval):\r\n",
        "    layer_size = len(predictions)\r\n",
        "    inp = Input(shape=(layer_size,3))\r\n",
        "    f0 = Flatten()(inp)\r\n",
        "    d0 = Dropout(0.2)(f0)\r\n",
        "    d0 = Dense(pow(layer_size, 4))(d0)\r\n",
        "    d1 = Dropout(0.2)(d0)\r\n",
        "    d1 = Dense(20 * layer_size)(d1)\r\n",
        "    b = BatchNormalization()(d1)\r\n",
        "    out = Dropout(0.2)(b)\r\n",
        "    out = Dense(3, activation='sigmoid')(out)\r\n",
        "\r\n",
        "    model = Model(inputs=inp, outputs=out)\r\n",
        "    metrics = [\r\n",
        "           keras.metrics.CategoricalAccuracy(),\r\n",
        "           keras.metrics.Precision(name='precision'),\r\n",
        "           keras.metrics.Recall(name='recall'),\r\n",
        "           f1_metrics,\r\n",
        "           #keras.metrics.TruePositives(name='tp'),\r\n",
        "           #keras.metrics.FalsePositives(name='fp'),\r\n",
        "           #keras.metrics.TrueNegatives(name='tn'),\r\n",
        "           #keras.metrics.FalseNegatives(name='fn'),\r\n",
        "  ]\r\n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=metrics)\r\n",
        "    model.summary()\r\n",
        "\r\n",
        "    x = np.array(list(zip(*np.squeeze(predictions))))\r\n",
        "    y = targets\r\n",
        "    print(np.shape(x))\r\n",
        "    print(np.shape(y))\r\n",
        "\r\n",
        "    xval = np.array(list(zip(*np.squeeze(xval))))\r\n",
        "    yval = yval\r\n",
        "    \r\n",
        "    history = model.fit(x=x, y=y, epochs=20, validation_data=(xval,yval), verbose=2)\r\n",
        "    #display_model_history(history_flat_CNN) \r\n",
        "    #plot_metrics(history_flat_CNN)\r\n",
        "    return model, history"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Torxmyr7Ox8z",
        "outputId": "71a65242-ab37-40e9-fa3e-2a90f388f409"
      },
      "source": [
        "y_train_cat = Y_train\r\n",
        "y_val_cat = Y_val\r\n",
        "y_test_cat = Y_test  \r\n",
        "stack_model, history = ensemble(train_predictions, y_train_cat, val_predictions, y_val_cat)\r\n",
        "\r\n",
        "stacked_test_predictions = np.array(list(zip(*np.squeeze(test_predictions))))\r\n",
        "stacked_test_predictions = stack_model.predict(stacked_test_predictions, batch_size=1024)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 5, 3)]            0         \n",
            "_________________________________________________________________\n",
            "flatten_2 (Flatten)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 625)               10000     \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 625)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 100)               62600     \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 100)               400       \n",
            "_________________________________________________________________\n",
            "dropout_8 (Dropout)          (None, 100)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 3)                 303       \n",
            "=================================================================\n",
            "Total params: 73,303\n",
            "Trainable params: 73,103\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n",
            "(87376, 5, 3)\n",
            "(87376, 3)\n",
            "Epoch 1/20\n",
            "2731/2731 - 13s - loss: 0.5131 - categorical_accuracy: 0.8175 - precision: 0.6788 - recall: 0.8964 - f1_metrics: 0.7735 - val_loss: 0.7006 - val_categorical_accuracy: 0.7221 - val_precision: 0.6575 - val_recall: 0.8242 - val_f1_metrics: 0.7319\n",
            "Epoch 2/20\n",
            "2731/2731 - 11s - loss: 0.4976 - categorical_accuracy: 0.8198 - precision: 0.7051 - recall: 0.9000 - f1_metrics: 0.7917 - val_loss: 0.7235 - val_categorical_accuracy: 0.7232 - val_precision: 0.6647 - val_recall: 0.8179 - val_f1_metrics: 0.7338\n",
            "Epoch 3/20\n",
            "2731/2731 - 11s - loss: 0.4980 - categorical_accuracy: 0.8191 - precision: 0.7106 - recall: 0.9006 - f1_metrics: 0.7952 - val_loss: 0.7160 - val_categorical_accuracy: 0.7232 - val_precision: 0.6626 - val_recall: 0.8173 - val_f1_metrics: 0.7322\n",
            "Epoch 4/20\n",
            "2731/2731 - 11s - loss: 0.4982 - categorical_accuracy: 0.8195 - precision: 0.7087 - recall: 0.9025 - f1_metrics: 0.7947 - val_loss: 0.7102 - val_categorical_accuracy: 0.7230 - val_precision: 0.6610 - val_recall: 0.8168 - val_f1_metrics: 0.7311\n",
            "Epoch 5/20\n",
            "2731/2731 - 11s - loss: 0.4953 - categorical_accuracy: 0.8204 - precision: 0.7170 - recall: 0.8987 - f1_metrics: 0.7983 - val_loss: 0.7211 - val_categorical_accuracy: 0.7230 - val_precision: 0.6580 - val_recall: 0.8190 - val_f1_metrics: 0.7301\n",
            "Epoch 6/20\n",
            "2731/2731 - 11s - loss: 0.4956 - categorical_accuracy: 0.8201 - precision: 0.7161 - recall: 0.8989 - f1_metrics: 0.7980 - val_loss: 0.6956 - val_categorical_accuracy: 0.7232 - val_precision: 0.6514 - val_recall: 0.8235 - val_f1_metrics: 0.7278\n",
            "Epoch 7/20\n",
            "2731/2731 - 11s - loss: 0.4950 - categorical_accuracy: 0.8212 - precision: 0.7267 - recall: 0.8959 - f1_metrics: 0.8033 - val_loss: 0.7201 - val_categorical_accuracy: 0.7224 - val_precision: 0.6685 - val_recall: 0.8056 - val_f1_metrics: 0.7310\n",
            "Epoch 8/20\n",
            "2731/2731 - 11s - loss: 0.4957 - categorical_accuracy: 0.8202 - precision: 0.7368 - recall: 0.8923 - f1_metrics: 0.8078 - val_loss: 0.7058 - val_categorical_accuracy: 0.7235 - val_precision: 0.6699 - val_recall: 0.8065 - val_f1_metrics: 0.7322\n",
            "Epoch 9/20\n",
            "2731/2731 - 11s - loss: 0.4976 - categorical_accuracy: 0.8197 - precision: 0.7389 - recall: 0.8890 - f1_metrics: 0.8077 - val_loss: 0.7059 - val_categorical_accuracy: 0.7226 - val_precision: 0.6722 - val_recall: 0.8042 - val_f1_metrics: 0.7327\n",
            "Epoch 10/20\n",
            "2731/2731 - 11s - loss: 0.4976 - categorical_accuracy: 0.8185 - precision: 0.7395 - recall: 0.8886 - f1_metrics: 0.8079 - val_loss: 0.7014 - val_categorical_accuracy: 0.7221 - val_precision: 0.6703 - val_recall: 0.8020 - val_f1_metrics: 0.7306\n",
            "Epoch 11/20\n",
            "2731/2731 - 11s - loss: 0.4945 - categorical_accuracy: 0.8201 - precision: 0.7480 - recall: 0.8865 - f1_metrics: 0.8120 - val_loss: 0.6993 - val_categorical_accuracy: 0.7223 - val_precision: 0.6698 - val_recall: 0.8041 - val_f1_metrics: 0.7312\n",
            "Epoch 12/20\n",
            "2731/2731 - 11s - loss: 0.4945 - categorical_accuracy: 0.8198 - precision: 0.7439 - recall: 0.8893 - f1_metrics: 0.8108 - val_loss: 0.7052 - val_categorical_accuracy: 0.7228 - val_precision: 0.6671 - val_recall: 0.8082 - val_f1_metrics: 0.7313\n",
            "Epoch 13/20\n",
            "2731/2731 - 11s - loss: 0.4953 - categorical_accuracy: 0.8204 - precision: 0.7408 - recall: 0.8900 - f1_metrics: 0.8093 - val_loss: 0.6984 - val_categorical_accuracy: 0.7224 - val_precision: 0.6683 - val_recall: 0.8069 - val_f1_metrics: 0.7314\n",
            "Epoch 14/20\n",
            "2731/2731 - 11s - loss: 0.4954 - categorical_accuracy: 0.8194 - precision: 0.7418 - recall: 0.8899 - f1_metrics: 0.8099 - val_loss: 0.7139 - val_categorical_accuracy: 0.7234 - val_precision: 0.6680 - val_recall: 0.8081 - val_f1_metrics: 0.7318\n",
            "Epoch 15/20\n",
            "2731/2731 - 11s - loss: 0.4944 - categorical_accuracy: 0.8198 - precision: 0.7414 - recall: 0.8919 - f1_metrics: 0.8104 - val_loss: 0.6996 - val_categorical_accuracy: 0.7234 - val_precision: 0.6617 - val_recall: 0.8137 - val_f1_metrics: 0.7303\n",
            "Epoch 16/20\n",
            "2731/2731 - 11s - loss: 0.4949 - categorical_accuracy: 0.8197 - precision: 0.7411 - recall: 0.8917 - f1_metrics: 0.8103 - val_loss: 0.7092 - val_categorical_accuracy: 0.7237 - val_precision: 0.6673 - val_recall: 0.8099 - val_f1_metrics: 0.7321\n",
            "Epoch 17/20\n",
            "2731/2731 - 11s - loss: 0.4964 - categorical_accuracy: 0.8197 - precision: 0.7426 - recall: 0.8906 - f1_metrics: 0.8105 - val_loss: 0.7046 - val_categorical_accuracy: 0.7235 - val_precision: 0.6682 - val_recall: 0.8100 - val_f1_metrics: 0.7326\n",
            "Epoch 18/20\n",
            "2731/2731 - 11s - loss: 0.4939 - categorical_accuracy: 0.8217 - precision: 0.7412 - recall: 0.8922 - f1_metrics: 0.8104 - val_loss: 0.6966 - val_categorical_accuracy: 0.7243 - val_precision: 0.6699 - val_recall: 0.8084 - val_f1_metrics: 0.7330\n",
            "Epoch 19/20\n",
            "2731/2731 - 11s - loss: 0.4960 - categorical_accuracy: 0.8194 - precision: 0.7449 - recall: 0.8892 - f1_metrics: 0.8114 - val_loss: 0.6915 - val_categorical_accuracy: 0.7217 - val_precision: 0.6685 - val_recall: 0.8082 - val_f1_metrics: 0.7320\n",
            "Epoch 20/20\n",
            "2731/2731 - 11s - loss: 0.4961 - categorical_accuracy: 0.8191 - precision: 0.7413 - recall: 0.8913 - f1_metrics: 0.8101 - val_loss: 0.6978 - val_categorical_accuracy: 0.7226 - val_precision: 0.6665 - val_recall: 0.8097 - val_f1_metrics: 0.7316\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Su6UMddaM01o",
        "outputId": "7e09094a-c594-4155-f7fe-355ba7c88a9c"
      },
      "source": [
        "indiv = []\r\n",
        "for model in members:\r\n",
        "  indiv.append(f1_metrics(y_test_cat, model.predict(X_test)))\r\n",
        "\r\n",
        "max(indiv)"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.7172153>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWJYjYGol_Cs",
        "outputId": "f3cd92aa-161a-4859-ec4d-24dfbcd8ba6c"
      },
      "source": [
        "stack_model.evaluate(np.array(list(zip(*np.squeeze(test_predictions)))),y_test_cat)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "357/357 [==============================] - 1s 3ms/step - loss: 0.6881 - categorical_accuracy: 0.7197 - precision: 0.6716 - recall: 0.8112 - f1_metrics: 0.7366\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.688101053237915,\n",
              " 0.7196637988090515,\n",
              " 0.6715952754020691,\n",
              " 0.8112414479255676,\n",
              " 0.7365813851356506]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    }
  ]
}