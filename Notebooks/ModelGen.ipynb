{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ModelGen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "-au6xYmT5TUc"
      },
      "source": [
        "import os\n",
        "import re\n",
        "import glob\n",
        "import struct\n",
        "from os import makedirs\n",
        "\n",
        "import numpy as np\n",
        "from numpy import asarray\n",
        "from numpy import zeros\n",
        "from nltk.stem.porter import *\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Input, Reshape, Conv2D, MaxPool2D, Dense, Dropout, Flatten, Embedding, Concatenate, Conv1D\n",
        "from keras.metrics import CategoricalAccuracy, Precision, Recall\n",
        "from keras import regularizers\n",
        "from keras import backend as K\n",
        "from keras.models import load_model\n",
        "\n",
        "import sklearn\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import metrics\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import RepeatedStratifiedKFold\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "\n",
        "import matplotlib.pyplot as plt\n"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iBtvw0JSyyJ0"
      },
      "source": [
        "Load the Dataset\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEun8UyZRDn9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "709f9fea-e4fe-46e3-8b9c-aa1bf52e2e28"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "33idFgY-BwTs"
      },
      "source": [
        "os.chdir(\"/content/drive/MyDrive/twit/train\")\n",
        "\n",
        "extension = 'csv'\n",
        "all_filenames = [i for i in glob.glob('*.{}'.format(extension))]\n",
        "\n",
        "#combine all files in the list\n",
        "combined_csv = pd.concat([pd.read_csv(f) for f in all_filenames ])\n",
        "#export to csv\n",
        "combined_csv.to_csv( \"aggregate.csv\", index=False, encoding='utf-8-sig')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kTFPtv5N5jVw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "17277455-203a-457f-a4db-fb5a3758c542"
      },
      "source": [
        "names = ['TweetID', 'Sentiment', 'Tweet']\n",
        "\n",
        "train = pd.read_csv('/content/drive/MyDrive/twit/train/aggregate.csv')\n",
        "\n",
        "train.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.551359e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>@Descending yeah yeah offer it now I'm halfway...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.191006e+09</td>\n",
              "      <td>positive</td>\n",
              "      <td>@coopes64 someone tweeted it this time, but I'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.556787e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>BTW I Don't live in the country I  am Suburbia...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.557363e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>@tiaralynn lol. i got the bg from createblog.c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.190198e+09</td>\n",
              "      <td>positive</td>\n",
              "      <td>@juzferyou well, not all that cheap i reckon b...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Column1   Column2                                            Column3\n",
              "0  1.551359e+09  negative  @Descending yeah yeah offer it now I'm halfway...\n",
              "1  2.191006e+09  positive  @coopes64 someone tweeted it this time, but I'...\n",
              "2  1.556787e+09  negative  BTW I Don't live in the country I  am Suburbia...\n",
              "3  1.557363e+09  negative  @tiaralynn lol. i got the bg from createblog.c...\n",
              "4  2.190198e+09  positive  @juzferyou well, not all that cheap i reckon b..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCffl4OOy7bR"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YI6wwcXYMlVQ"
      },
      "source": [
        "def remove_pattern(input_txt, pattern):\n",
        "  r = re.findall(pattern, input_txt)\n",
        "  for i in r:\n",
        "    input_txt = re.sub(i, '', input_txt)        \n",
        "  return input_txt\n",
        "\n",
        "def clean_tweets(frame, column_name):\n",
        "  frame = frame.drop_duplicates().reset_index(drop=True) #remove duplicate rows\n",
        "  frame['Tweet_Clean_Text'] = np.vectorize(remove_pattern)(frame[column_name], \"RT @[\\w]*:\") #remove twitter return handle\n",
        "  frame.Tweet_Clean_Text = np.vectorize(remove_pattern)(frame['Tweet_Clean_Text'], \"@[\\w]*\") #remove twitter handle\n",
        "  frame.Tweet_Clean_Text = np.vectorize(remove_pattern)(frame['Tweet_Clean_Text'], \"https?://[A-Za-z0-9./]*\") #remove URLs\n",
        "  frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.str.replace(\"[^a-zA-Z#]\", \" \") #remove special characters except for #\n",
        "  frame.Tweet_Clean_Text = frame.Tweet_Clean_Text.replace('\\s+', ' ', regex=True) #remove extra spaces in between words\n",
        "\n",
        "  return frame"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3Et4zHBMzXQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c3400b9a-8e74-43af-a27a-de362b30560e"
      },
      "source": [
        "train_set = clean_tweets(train, 'Column3')\n",
        "train_set.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Tweet_Clean_Text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.551359e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>@Descending yeah yeah offer it now I'm halfway...</td>\n",
              "      <td>yeah yeah offer it now I m halfway home</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.191006e+09</td>\n",
              "      <td>positive</td>\n",
              "      <td>@coopes64 someone tweeted it this time, but I'...</td>\n",
              "      <td>someone tweeted it this time but I ve seen it...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.556787e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>BTW I Don't live in the country I  am Suburbia...</td>\n",
              "      <td>BTW I Don t live in the country I am Suburbia ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.557363e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>@tiaralynn lol. i got the bg from createblog.c...</td>\n",
              "      <td>lol i got the bg from createblog com i was go...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.190198e+09</td>\n",
              "      <td>positive</td>\n",
              "      <td>@juzferyou well, not all that cheap i reckon b...</td>\n",
              "      <td>well not all that cheap i reckon but cute def...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        Column1  ...                                   Tweet_Clean_Text\n",
              "0  1.551359e+09  ...           yeah yeah offer it now I m halfway home \n",
              "1  2.191006e+09  ...   someone tweeted it this time but I ve seen it...\n",
              "2  1.556787e+09  ...  BTW I Don t live in the country I am Suburbia ...\n",
              "3  1.557363e+09  ...   lol i got the bg from createblog com i was go...\n",
              "4  2.190198e+09  ...   well not all that cheap i reckon but cute def...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz2kEFcsaT0b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "092fb4ad-d763-48c4-b51a-f8733b0a72cb"
      },
      "source": [
        "train_set[\"Sentiment_Value\"] = train_set[\"Column2\"].map({\"neutral\": 0, \"positive\": 1, \"negative\": 2})\r\n",
        "label = to_categorical(train_set[\"Sentiment_Value\"], 3)\r\n",
        "train_set"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Column1</th>\n",
              "      <th>Column2</th>\n",
              "      <th>Column3</th>\n",
              "      <th>Tweet_Clean_Text</th>\n",
              "      <th>Sentiment_Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1.551359e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>@Descending yeah yeah offer it now I'm halfway...</td>\n",
              "      <td>yeah yeah offer it now I m halfway home</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2.191006e+09</td>\n",
              "      <td>positive</td>\n",
              "      <td>@coopes64 someone tweeted it this time, but I'...</td>\n",
              "      <td>someone tweeted it this time but I ve seen it...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1.556787e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>BTW I Don't live in the country I  am Suburbia...</td>\n",
              "      <td>BTW I Don t live in the country I am Suburbia ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.557363e+09</td>\n",
              "      <td>negative</td>\n",
              "      <td>@tiaralynn lol. i got the bg from createblog.c...</td>\n",
              "      <td>lol i got the bg from createblog com i was go...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2.190198e+09</td>\n",
              "      <td>positive</td>\n",
              "      <td>@juzferyou well, not all that cheap i reckon b...</td>\n",
              "      <td>well not all that cheap i reckon but cute def...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114213</th>\n",
              "      <td>6.390170e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@YouAreMyArsenal Wouldn't surprise me if we en...</td>\n",
              "      <td>Wouldn t surprise me if we enquired He can t ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114214</th>\n",
              "      <td>6.402770e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
              "      <td>Rib injury for Zlatan against Russia is a big ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114215</th>\n",
              "      <td>6.402970e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>Noooooo! I was hoping to see Zlatan being Zlat...</td>\n",
              "      <td>Noooooo I was hoping to see Zlatan being Zlata...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114216</th>\n",
              "      <td>6.410170e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@Fronsoir Zlatan has never done it on a wet Tu...</td>\n",
              "      <td>Zlatan has never done it on a wet Tuesday nig...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114217</th>\n",
              "      <td>6.413960e+17</td>\n",
              "      <td>neutral</td>\n",
              "      <td>@ZIatanVines  how many goals Zlatan intends to...</td>\n",
              "      <td>how many goals Zlatan intends to serve into t...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>114218 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "             Column1  ... Sentiment_Value\n",
              "0       1.551359e+09  ...               2\n",
              "1       2.191006e+09  ...               1\n",
              "2       1.556787e+09  ...               2\n",
              "3       1.557363e+09  ...               2\n",
              "4       2.190198e+09  ...               1\n",
              "...              ...  ...             ...\n",
              "114213  6.390170e+17  ...               0\n",
              "114214  6.402770e+17  ...               0\n",
              "114215  6.402970e+17  ...               0\n",
              "114216  6.410170e+17  ...               0\n",
              "114217  6.413960e+17  ...               0\n",
              "\n",
              "[114218 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbRAhnz3FXOX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "343a3e78-eae9-4429-e3e0-1c5950f521ee"
      },
      "source": [
        "y_labels = train_set['Sentiment_Value']\r\n",
        "y_labels.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(114218,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lPrL0u6wqIuI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1da1b236-0679-447f-d498-3a6d223d83b0"
      },
      "source": [
        "train['l'] = train_set['Tweet_Clean_Text'].apply(lambda x: len(str(x).split(' ')))\n",
        "print(\"mean length of sentence: \" + str(train.l.mean()))\n",
        "print(\"max length of sentence: \" + str(train.l.max()))\n",
        "print(\"std dev length of sentence: \" + str(train.l.std()))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mean length of sentence: 17.38020277014131\n",
            "max length of sentence: 47.0\n",
            "std dev length of sentence: 6.9299730337355\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmNsjX3Z1K7Q"
      },
      "source": [
        "sequence_length = 47 #using the maximum length "
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7mrlqPjcqhUI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac52dc08-44f0-4b72-e98e-d0f7819ad116"
      },
      "source": [
        "max_features = 2500\n",
        "tokenizer = Tokenizer(num_words=max_features, split=' ', oov_token='<unw>')\n",
        "tokenizer.fit_on_texts(train_set['Tweet_Clean_Text'].values)\n",
        "\n",
        "X = tokenizer.texts_to_sequences(train_set['Tweet_Clean_Text'].values)\n",
        "X = pad_sequences(X, sequence_length)\n",
        "x_train = X\n",
        "\n",
        "print(\"training size \" + str(len(x_train)))\n",
        "\n",
        "voc_size = len(tokenizer.word_index) + 1\n",
        "print(\"Vocab size: \", voc_size)\n",
        "print(\"Input shape: \", x_train.shape)\n",
        "print(\"Y_shape: \" , y_labels.shape)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "training size 114218\n",
            "Vocab size:  63987\n",
            "Input shape:  (114218, 47)\n",
            "Y_shape:  (114218,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsv4hwJPzD7o"
      },
      "source": [
        "Spliting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AhX8T4-NBO-A"
      },
      "source": [
        "x_train, X_test, y_labels, Y_test = train_test_split(x_train, y_labels, test_size=0.10, shuffle=False, random_state=10)\r\n",
        "\r\n",
        "X_train, X_dev, Y_train, Y_dev = train_test_split(x_train, y_labels, test_size=0.15, shuffle=True, random_state=10)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ml2XYDrzKsZ"
      },
      "source": [
        "GloVe Embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZf4uIiIm_6A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "642767d2-ee18-4771-f59e-118ffc172ed2"
      },
      "source": [
        "embeddings_index = dict()\r\n",
        "f = open('/content/drive/MyDrive/glove.twitter.27B/glove.twitter.27B.200d.txt')\r\n",
        "for line in f:\r\n",
        "\tvalues = line.split()\r\n",
        "\tword = values[0]\r\n",
        "\tcoefs = asarray(values[1:], dtype='float32')\r\n",
        "\tembeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "print('Loaded %s word vectors.' % len(embeddings_index))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded 1193514 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoMjKu5Ln5ip"
      },
      "source": [
        "embedding_dim = 200\r\n",
        "embedding_matrix = np.zeros((voc_size, embedding_dim))\r\n",
        "for word, i in tokenizer.word_index.items():\r\n",
        "\tembedding_vector = embeddings_index.get(word)\r\n",
        "\tif embedding_vector is not None:\r\n",
        "\t\tembedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNGi4e67iyO9"
      },
      "source": [
        "Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zDGOkChP4YNx"
      },
      "source": [
        "def recall_score(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\r\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\r\n",
        "    recall_score.__name__ = 'recall'\r\n",
        "    return recall\r\n",
        "\r\n",
        "def precision_score(y_true, y_pred):\r\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\r\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\r\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\r\n",
        "    precision_score.__name__ = 'precision'\r\n",
        "    return precision\r\n",
        "\r\n",
        "def f1_metrics(y_true, y_pred):\r\n",
        "    precision = precision_score(y_true, y_pred)\r\n",
        "    recall = recall_score(y_true, y_pred)\r\n",
        "    f1_metrics.__name__ = 'f1'\r\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14wD5oBm5ftK"
      },
      "source": [
        "from keras.utils import to_categorical\r\n",
        "from keras import layers\r\n",
        "\r\n",
        "def model_gen(filter_sizes):\r\n",
        "\r\n",
        "  model_checkpoint = tf.keras.callbacks.ModelCheckpoint(\r\n",
        "      filepath= 'models/flatCNN' + str(filter_sizes) + '.h5',\r\n",
        "      save_weights_only = False,\r\n",
        "      monitor = 'val_f1',\r\n",
        "      mode= 'max',\r\n",
        "      save_best_only= True\r\n",
        "  )\r\n",
        "\r\n",
        "  early_stopping_callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=2)\r\n",
        "\r\n",
        "  reduce_lr_callback = keras.callbacks.ReduceLROnPlateau(monitor='val_categorical_accuracy', factor=0.2, patience=2, min_lr=0.00001)\r\n",
        "\r\n",
        "  output_dims = 200\r\n",
        "  lstm_out = filter_sizes\r\n",
        "\r\n",
        "  model = keras.Sequential([\r\n",
        "      layers.Embedding(input_dim=voc_size, output_dim=output_dims, input_length=X.shape[1], weights=[embedding_matrix]),\r\n",
        "      layers.SpatialDropout1D(0.2),\r\n",
        "      layers.Bidirectional(layers.LSTM(units=lstm_out, dropout=0.2, recurrent_dropout=0.2)),\r\n",
        "      layers.Dense(units=3, activation='softmax')\r\n",
        "      ])\r\n",
        "\r\n",
        "  metrics = [\r\n",
        "           keras.metrics.CategoricalAccuracy(),\r\n",
        "           keras.metrics.Precision(name='precision'),\r\n",
        "           keras.metrics.Recall(name='recall'),\r\n",
        "           f1_metrics,\r\n",
        "           #keras.metrics.TruePositives(name='tp'),\r\n",
        "           #keras.metrics.FalsePositives(name='fp'),\r\n",
        "           #keras.metrics.TrueNegatives(name='tn'),\r\n",
        "           #keras.metrics.FalseNegatives(name='fn'),\r\n",
        "  ]\r\n",
        "\r\n",
        "  model.compile(optimizer='adam',\r\n",
        "              loss=keras.losses.CategoricalCrossentropy(),\r\n",
        "              metrics=metrics\r\n",
        "              )\r\n",
        "\r\n",
        "  history = model.fit(X_train,\r\n",
        "                    to_categorical(Y_train),\r\n",
        "                    batch_size=3000,\r\n",
        "                    epochs=20,\r\n",
        "                    validation_split=0.05,\r\n",
        "                    shuffle=True,\r\n",
        "                    callbacks=[model_checkpoint, early_stopping_callback, reduce_lr_callback]\r\n",
        "  )\r\n",
        "\r\n",
        "  return model, history\r\n",
        "\r\n",
        "\r\n"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5WEwkiOJD56C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "125e6fea-ffc9-425b-9b27-206db1a65a5a"
      },
      "source": [
        "filter_sizes = [\r\n",
        "                200,256,352,456,532\r\n",
        "                ]\r\n",
        "models = []\r\n",
        "best_indiv = 0.0\r\n",
        "for filter_size in filter_sizes:\r\n",
        "  model, history = model_gen(filter_size)\r\n",
        "  models.append(model)\r\n",
        "  best_indiv = max(best_indiv, max(history.history['val_f1']))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "28/28 [==============================] - 24s 721ms/step - loss: 1.0036 - categorical_accuracy: 0.4899 - precision: 0.6512 - recall: 0.1527 - f1: 0.2085 - val_loss: 0.7732 - val_categorical_accuracy: 0.6580 - val_precision: 0.6928 - val_recall: 0.5848 - val_f1: 0.6326\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 20s 707ms/step - loss: 0.7752 - categorical_accuracy: 0.6454 - precision: 0.6882 - recall: 0.5671 - f1: 0.6218 - val_loss: 0.7032 - val_categorical_accuracy: 0.6901 - val_precision: 0.7211 - val_recall: 0.6304 - val_f1: 0.6717\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 20s 709ms/step - loss: 0.7176 - categorical_accuracy: 0.6782 - precision: 0.7149 - recall: 0.6106 - f1: 0.6586 - val_loss: 0.6829 - val_categorical_accuracy: 0.6986 - val_precision: 0.7424 - val_recall: 0.6411 - val_f1: 0.6869\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 20s 711ms/step - loss: 0.6948 - categorical_accuracy: 0.6874 - precision: 0.7239 - recall: 0.6271 - f1: 0.6720 - val_loss: 0.6670 - val_categorical_accuracy: 0.7031 - val_precision: 0.7399 - val_recall: 0.6544 - val_f1: 0.6926\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 20s 715ms/step - loss: 0.6656 - categorical_accuracy: 0.7053 - precision: 0.7386 - recall: 0.6511 - f1: 0.6921 - val_loss: 0.6616 - val_categorical_accuracy: 0.7137 - val_precision: 0.7406 - val_recall: 0.6802 - val_f1: 0.7070\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 20s 712ms/step - loss: 0.6556 - categorical_accuracy: 0.7096 - precision: 0.7416 - recall: 0.6575 - f1: 0.6970 - val_loss: 0.6541 - val_categorical_accuracy: 0.7100 - val_precision: 0.7367 - val_recall: 0.6718 - val_f1: 0.7000\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 20s 709ms/step - loss: 0.6463 - categorical_accuracy: 0.7116 - precision: 0.7405 - recall: 0.6652 - f1: 0.7008 - val_loss: 0.6470 - val_categorical_accuracy: 0.7150 - val_precision: 0.7439 - val_recall: 0.6807 - val_f1: 0.7067\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 20s 702ms/step - loss: 0.6309 - categorical_accuracy: 0.7215 - precision: 0.7502 - recall: 0.6770 - f1: 0.7117 - val_loss: 0.6627 - val_categorical_accuracy: 0.7148 - val_precision: 0.7369 - val_recall: 0.6871 - val_f1: 0.7100\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 20s 711ms/step - loss: 0.6221 - categorical_accuracy: 0.7242 - precision: 0.7515 - recall: 0.6836 - f1: 0.7159 - val_loss: 0.6402 - val_categorical_accuracy: 0.7221 - val_precision: 0.7453 - val_recall: 0.6846 - val_f1: 0.7110\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 20s 721ms/step - loss: 0.6079 - categorical_accuracy: 0.7337 - precision: 0.7605 - recall: 0.6920 - f1: 0.7246 - val_loss: 0.6380 - val_categorical_accuracy: 0.7212 - val_precision: 0.7461 - val_recall: 0.6873 - val_f1: 0.7135\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 21s 732ms/step - loss: 0.6005 - categorical_accuracy: 0.7339 - precision: 0.7602 - recall: 0.6956 - f1: 0.7265 - val_loss: 0.6438 - val_categorical_accuracy: 0.7226 - val_precision: 0.7415 - val_recall: 0.6940 - val_f1: 0.7164\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 20s 724ms/step - loss: 0.5897 - categorical_accuracy: 0.7419 - precision: 0.7670 - recall: 0.7052 - f1: 0.7348 - val_loss: 0.6324 - val_categorical_accuracy: 0.7263 - val_precision: 0.7506 - val_recall: 0.6883 - val_f1: 0.7168\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 20s 721ms/step - loss: 0.5868 - categorical_accuracy: 0.7412 - precision: 0.7667 - recall: 0.7035 - f1: 0.7337 - val_loss: 0.6325 - val_categorical_accuracy: 0.7313 - val_precision: 0.7510 - val_recall: 0.6938 - val_f1: 0.7195\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 20s 714ms/step - loss: 0.5786 - categorical_accuracy: 0.7452 - precision: 0.7703 - recall: 0.7087 - f1: 0.7382 - val_loss: 0.6393 - val_categorical_accuracy: 0.7306 - val_precision: 0.7487 - val_recall: 0.7059 - val_f1: 0.7255\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_2 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "28/28 [==============================] - 27s 800ms/step - loss: 0.9654 - categorical_accuracy: 0.5235 - precision: 0.6434 - recall: 0.2112 - f1: 0.2670 - val_loss: 0.7450 - val_categorical_accuracy: 0.6681 - val_precision: 0.7040 - val_recall: 0.6038 - val_f1: 0.6481\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 22s 788ms/step - loss: 0.7634 - categorical_accuracy: 0.6511 - precision: 0.6918 - recall: 0.5760 - f1: 0.6286 - val_loss: 0.7021 - val_categorical_accuracy: 0.6933 - val_precision: 0.7239 - val_recall: 0.6384 - val_f1: 0.6775\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 22s 784ms/step - loss: 0.7183 - categorical_accuracy: 0.6757 - precision: 0.7133 - recall: 0.6091 - f1: 0.6570 - val_loss: 0.6798 - val_categorical_accuracy: 0.7008 - val_precision: 0.7308 - val_recall: 0.6436 - val_f1: 0.6815\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 22s 775ms/step - loss: 0.6894 - categorical_accuracy: 0.6897 - precision: 0.7265 - recall: 0.6329 - f1: 0.6765 - val_loss: 0.6675 - val_categorical_accuracy: 0.7020 - val_precision: 0.7367 - val_recall: 0.6505 - val_f1: 0.6875\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 22s 777ms/step - loss: 0.6697 - categorical_accuracy: 0.7018 - precision: 0.7341 - recall: 0.6470 - f1: 0.6878 - val_loss: 0.6550 - val_categorical_accuracy: 0.7084 - val_precision: 0.7347 - val_recall: 0.6713 - val_f1: 0.6980\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 22s 791ms/step - loss: 0.6528 - categorical_accuracy: 0.7112 - precision: 0.7403 - recall: 0.6620 - f1: 0.6990 - val_loss: 0.6551 - val_categorical_accuracy: 0.7063 - val_precision: 0.7363 - val_recall: 0.6718 - val_f1: 0.6993\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 22s 784ms/step - loss: 0.6381 - categorical_accuracy: 0.7176 - precision: 0.7463 - recall: 0.6709 - f1: 0.7066 - val_loss: 0.6536 - val_categorical_accuracy: 0.7203 - val_precision: 0.7418 - val_recall: 0.6791 - val_f1: 0.7061\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 22s 783ms/step - loss: 0.6267 - categorical_accuracy: 0.7223 - precision: 0.7505 - recall: 0.6798 - f1: 0.7134 - val_loss: 0.6420 - val_categorical_accuracy: 0.7164 - val_precision: 0.7402 - val_recall: 0.6855 - val_f1: 0.7088\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 22s 770ms/step - loss: 0.6199 - categorical_accuracy: 0.7269 - precision: 0.7559 - recall: 0.6831 - f1: 0.7176 - val_loss: 0.6410 - val_categorical_accuracy: 0.7251 - val_precision: 0.7451 - val_recall: 0.6944 - val_f1: 0.7182\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 22s 783ms/step - loss: 0.6099 - categorical_accuracy: 0.7306 - precision: 0.7563 - recall: 0.6898 - f1: 0.7215 - val_loss: 0.6385 - val_categorical_accuracy: 0.7194 - val_precision: 0.7444 - val_recall: 0.6825 - val_f1: 0.7105\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 22s 771ms/step - loss: 0.6028 - categorical_accuracy: 0.7339 - precision: 0.7603 - recall: 0.6960 - f1: 0.7267 - val_loss: 0.6393 - val_categorical_accuracy: 0.7269 - val_precision: 0.7449 - val_recall: 0.6972 - val_f1: 0.7198\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 22s 781ms/step - loss: 0.5950 - categorical_accuracy: 0.7386 - precision: 0.7647 - recall: 0.7024 - f1: 0.7322 - val_loss: 0.6344 - val_categorical_accuracy: 0.7235 - val_precision: 0.7489 - val_recall: 0.6928 - val_f1: 0.7171\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 22s 773ms/step - loss: 0.5835 - categorical_accuracy: 0.7430 - precision: 0.7674 - recall: 0.7073 - f1: 0.7361 - val_loss: 0.6334 - val_categorical_accuracy: 0.7297 - val_precision: 0.7473 - val_recall: 0.7006 - val_f1: 0.7215\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 22s 775ms/step - loss: 0.5778 - categorical_accuracy: 0.7461 - precision: 0.7688 - recall: 0.7125 - f1: 0.7396 - val_loss: 0.6296 - val_categorical_accuracy: 0.7269 - val_precision: 0.7526 - val_recall: 0.6935 - val_f1: 0.7215\n",
            "Epoch 15/20\n",
            "28/28 [==============================] - 22s 775ms/step - loss: 0.5727 - categorical_accuracy: 0.7473 - precision: 0.7717 - recall: 0.7133 - f1: 0.7413 - val_loss: 0.6307 - val_categorical_accuracy: 0.7297 - val_precision: 0.7511 - val_recall: 0.7011 - val_f1: 0.7236\n",
            "Epoch 16/20\n",
            "28/28 [==============================] - 22s 772ms/step - loss: 0.5600 - categorical_accuracy: 0.7539 - precision: 0.7756 - recall: 0.7237 - f1: 0.7488 - val_loss: 0.6259 - val_categorical_accuracy: 0.7320 - val_precision: 0.7543 - val_recall: 0.7034 - val_f1: 0.7270\n",
            "Epoch 17/20\n",
            "28/28 [==============================] - 21s 764ms/step - loss: 0.5509 - categorical_accuracy: 0.7574 - precision: 0.7795 - recall: 0.7271 - f1: 0.7524 - val_loss: 0.6285 - val_categorical_accuracy: 0.7331 - val_precision: 0.7533 - val_recall: 0.7066 - val_f1: 0.7284\n",
            "Epoch 18/20\n",
            "28/28 [==============================] - 22s 784ms/step - loss: 0.5504 - categorical_accuracy: 0.7612 - precision: 0.7821 - recall: 0.7320 - f1: 0.7562 - val_loss: 0.6271 - val_categorical_accuracy: 0.7288 - val_precision: 0.7496 - val_recall: 0.7015 - val_f1: 0.7240\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_3 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "28/28 [==============================] - 33s 1s/step - loss: 0.9601 - categorical_accuracy: 0.5331 - precision: 0.6121 - recall: 0.2348 - f1: 0.2977 - val_loss: 0.7424 - val_categorical_accuracy: 0.6782 - val_precision: 0.7122 - val_recall: 0.6011 - val_f1: 0.6503\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 28s 986ms/step - loss: 0.7608 - categorical_accuracy: 0.6554 - precision: 0.6967 - recall: 0.5773 - f1: 0.6314 - val_loss: 0.6937 - val_categorical_accuracy: 0.7004 - val_precision: 0.7274 - val_recall: 0.6381 - val_f1: 0.6779\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 28s 992ms/step - loss: 0.7131 - categorical_accuracy: 0.6779 - precision: 0.7138 - recall: 0.6158 - f1: 0.6612 - val_loss: 0.6760 - val_categorical_accuracy: 0.7029 - val_precision: 0.7393 - val_recall: 0.6349 - val_f1: 0.6807\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 28s 992ms/step - loss: 0.6880 - categorical_accuracy: 0.6907 - precision: 0.7267 - recall: 0.6300 - f1: 0.6748 - val_loss: 0.6684 - val_categorical_accuracy: 0.7125 - val_precision: 0.7441 - val_recall: 0.6596 - val_f1: 0.6969\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 28s 993ms/step - loss: 0.6686 - categorical_accuracy: 0.7017 - precision: 0.7354 - recall: 0.6470 - f1: 0.6884 - val_loss: 0.6552 - val_categorical_accuracy: 0.7082 - val_precision: 0.7459 - val_recall: 0.6526 - val_f1: 0.6926\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 28s 985ms/step - loss: 0.6501 - categorical_accuracy: 0.7116 - precision: 0.7447 - recall: 0.6580 - f1: 0.6987 - val_loss: 0.6564 - val_categorical_accuracy: 0.7020 - val_precision: 0.7374 - val_recall: 0.6638 - val_f1: 0.6947\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 28s 984ms/step - loss: 0.6406 - categorical_accuracy: 0.7176 - precision: 0.7473 - recall: 0.6713 - f1: 0.7072 - val_loss: 0.6468 - val_categorical_accuracy: 0.7176 - val_precision: 0.7451 - val_recall: 0.6791 - val_f1: 0.7091\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 28s 999ms/step - loss: 0.6301 - categorical_accuracy: 0.7192 - precision: 0.7484 - recall: 0.6763 - f1: 0.7105 - val_loss: 0.6439 - val_categorical_accuracy: 0.7194 - val_precision: 0.7474 - val_recall: 0.6780 - val_f1: 0.7088\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 28s 995ms/step - loss: 0.6278 - categorical_accuracy: 0.7239 - precision: 0.7539 - recall: 0.6801 - f1: 0.7151 - val_loss: 0.6446 - val_categorical_accuracy: 0.7155 - val_precision: 0.7451 - val_recall: 0.6825 - val_f1: 0.7105\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 28s 997ms/step - loss: 0.6271 - categorical_accuracy: 0.7247 - precision: 0.7543 - recall: 0.6804 - f1: 0.7154 - val_loss: 0.6411 - val_categorical_accuracy: 0.7178 - val_precision: 0.7477 - val_recall: 0.6839 - val_f1: 0.7128\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 28s 990ms/step - loss: 0.6207 - categorical_accuracy: 0.7257 - precision: 0.7543 - recall: 0.6817 - f1: 0.7162 - val_loss: 0.6413 - val_categorical_accuracy: 0.7192 - val_precision: 0.7459 - val_recall: 0.6841 - val_f1: 0.7126\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 27s 982ms/step - loss: 0.6226 - categorical_accuracy: 0.7225 - precision: 0.7525 - recall: 0.6818 - f1: 0.7154 - val_loss: 0.6411 - val_categorical_accuracy: 0.7210 - val_precision: 0.7468 - val_recall: 0.6864 - val_f1: 0.7138\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 28s 1s/step - loss: 0.6179 - categorical_accuracy: 0.7258 - precision: 0.7532 - recall: 0.6832 - f1: 0.7165 - val_loss: 0.6404 - val_categorical_accuracy: 0.7210 - val_precision: 0.7488 - val_recall: 0.6844 - val_f1: 0.7135\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 28s 999ms/step - loss: 0.6181 - categorical_accuracy: 0.7268 - precision: 0.7563 - recall: 0.6838 - f1: 0.7182 - val_loss: 0.6405 - val_categorical_accuracy: 0.7210 - val_precision: 0.7483 - val_recall: 0.6873 - val_f1: 0.7152\n",
            "Epoch 15/20\n",
            "28/28 [==============================] - 28s 988ms/step - loss: 0.6156 - categorical_accuracy: 0.7282 - precision: 0.7569 - recall: 0.6874 - f1: 0.7205 - val_loss: 0.6401 - val_categorical_accuracy: 0.7212 - val_precision: 0.7476 - val_recall: 0.6853 - val_f1: 0.7141\n",
            "Epoch 16/20\n",
            "28/28 [==============================] - 28s 990ms/step - loss: 0.6130 - categorical_accuracy: 0.7295 - precision: 0.7589 - recall: 0.6876 - f1: 0.7215 - val_loss: 0.6401 - val_categorical_accuracy: 0.7224 - val_precision: 0.7481 - val_recall: 0.6857 - val_f1: 0.7143\n",
            "Epoch 17/20\n",
            "28/28 [==============================] - 28s 990ms/step - loss: 0.6208 - categorical_accuracy: 0.7259 - precision: 0.7538 - recall: 0.6825 - f1: 0.7164 - val_loss: 0.6401 - val_categorical_accuracy: 0.7228 - val_precision: 0.7478 - val_recall: 0.6860 - val_f1: 0.7144\n",
            "Epoch 18/20\n",
            "28/28 [==============================] - 28s 984ms/step - loss: 0.6213 - categorical_accuracy: 0.7267 - precision: 0.7551 - recall: 0.6826 - f1: 0.7170 - val_loss: 0.6401 - val_categorical_accuracy: 0.7219 - val_precision: 0.7475 - val_recall: 0.6878 - val_f1: 0.7149\n",
            "Epoch 19/20\n",
            "28/28 [==============================] - 28s 988ms/step - loss: 0.6190 - categorical_accuracy: 0.7253 - precision: 0.7521 - recall: 0.6822 - f1: 0.7154 - val_loss: 0.6399 - val_categorical_accuracy: 0.7226 - val_precision: 0.7490 - val_recall: 0.6864 - val_f1: 0.7153\n",
            "Epoch 20/20\n",
            "28/28 [==============================] - 28s 997ms/step - loss: 0.6180 - categorical_accuracy: 0.7271 - precision: 0.7551 - recall: 0.6848 - f1: 0.7182 - val_loss: 0.6399 - val_categorical_accuracy: 0.7219 - val_precision: 0.7478 - val_recall: 0.6867 - val_f1: 0.7146\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "28/28 [==============================] - 41s 1s/step - loss: 0.9701 - categorical_accuracy: 0.5198 - precision: 0.6394 - recall: 0.2310 - f1: 0.2955 - val_loss: 0.7535 - val_categorical_accuracy: 0.6697 - val_precision: 0.7057 - val_recall: 0.5928 - val_f1: 0.6462\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.7685 - categorical_accuracy: 0.6506 - precision: 0.6918 - recall: 0.5719 - f1: 0.6262 - val_loss: 0.7048 - val_categorical_accuracy: 0.6926 - val_precision: 0.7201 - val_recall: 0.6390 - val_f1: 0.6739\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.7238 - categorical_accuracy: 0.6730 - precision: 0.7127 - recall: 0.6061 - f1: 0.6550 - val_loss: 0.6846 - val_categorical_accuracy: 0.7022 - val_precision: 0.7343 - val_recall: 0.6539 - val_f1: 0.6891\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6924 - categorical_accuracy: 0.6896 - precision: 0.7254 - recall: 0.6310 - f1: 0.6749 - val_loss: 0.6627 - val_categorical_accuracy: 0.7121 - val_precision: 0.7463 - val_recall: 0.6592 - val_f1: 0.6975\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6716 - categorical_accuracy: 0.7008 - precision: 0.7337 - recall: 0.6489 - f1: 0.6887 - val_loss: 0.6540 - val_categorical_accuracy: 0.7118 - val_precision: 0.7476 - val_recall: 0.6631 - val_f1: 0.6997\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6499 - categorical_accuracy: 0.7129 - precision: 0.7449 - recall: 0.6611 - f1: 0.7005 - val_loss: 0.6508 - val_categorical_accuracy: 0.7107 - val_precision: 0.7437 - val_recall: 0.6754 - val_f1: 0.7057\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6376 - categorical_accuracy: 0.7182 - precision: 0.7473 - recall: 0.6731 - f1: 0.7083 - val_loss: 0.6428 - val_categorical_accuracy: 0.7139 - val_precision: 0.7455 - val_recall: 0.6738 - val_f1: 0.7055\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6314 - categorical_accuracy: 0.7217 - precision: 0.7508 - recall: 0.6760 - f1: 0.7115 - val_loss: 0.6456 - val_categorical_accuracy: 0.7178 - val_precision: 0.7441 - val_recall: 0.6837 - val_f1: 0.7100\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 36s 1s/step - loss: 0.6289 - categorical_accuracy: 0.7219 - precision: 0.7502 - recall: 0.6805 - f1: 0.7136 - val_loss: 0.6435 - val_categorical_accuracy: 0.7217 - val_precision: 0.7487 - val_recall: 0.6807 - val_f1: 0.7118\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "WARNING:tensorflow:Layer lstm_5 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
            "Epoch 1/20\n",
            "28/28 [==============================] - 48s 2s/step - loss: 0.9876 - categorical_accuracy: 0.5132 - precision: 0.5729 - recall: 0.2337 - f1: 0.2970 - val_loss: 0.7530 - val_categorical_accuracy: 0.6688 - val_precision: 0.7044 - val_recall: 0.5892 - val_f1: 0.6405\n",
            "Epoch 2/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.7642 - categorical_accuracy: 0.6521 - precision: 0.6903 - recall: 0.5768 - f1: 0.6284 - val_loss: 0.7019 - val_categorical_accuracy: 0.6940 - val_precision: 0.7345 - val_recall: 0.6180 - val_f1: 0.6672\n",
            "Epoch 3/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.7179 - categorical_accuracy: 0.6809 - precision: 0.7179 - recall: 0.6078 - f1: 0.6583 - val_loss: 0.6758 - val_categorical_accuracy: 0.7031 - val_precision: 0.7412 - val_recall: 0.6436 - val_f1: 0.6865\n",
            "Epoch 4/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.6896 - categorical_accuracy: 0.6910 - precision: 0.7264 - recall: 0.6312 - f1: 0.6754 - val_loss: 0.6604 - val_categorical_accuracy: 0.7134 - val_precision: 0.7478 - val_recall: 0.6509 - val_f1: 0.6929\n",
            "Epoch 5/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.6671 - categorical_accuracy: 0.7028 - precision: 0.7363 - recall: 0.6492 - f1: 0.6900 - val_loss: 0.6505 - val_categorical_accuracy: 0.7160 - val_precision: 0.7490 - val_recall: 0.6672 - val_f1: 0.7015\n",
            "Epoch 6/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.6489 - categorical_accuracy: 0.7137 - precision: 0.7439 - recall: 0.6644 - f1: 0.7019 - val_loss: 0.6481 - val_categorical_accuracy: 0.7139 - val_precision: 0.7414 - val_recall: 0.6661 - val_f1: 0.6996\n",
            "Epoch 7/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.6402 - categorical_accuracy: 0.7149 - precision: 0.7465 - recall: 0.6679 - f1: 0.7050 - val_loss: 0.6470 - val_categorical_accuracy: 0.7185 - val_precision: 0.7428 - val_recall: 0.6869 - val_f1: 0.7125\n",
            "Epoch 8/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.6249 - categorical_accuracy: 0.7249 - precision: 0.7516 - recall: 0.6813 - f1: 0.7147 - val_loss: 0.6418 - val_categorical_accuracy: 0.7228 - val_precision: 0.7448 - val_recall: 0.6905 - val_f1: 0.7155\n",
            "Epoch 9/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.6128 - categorical_accuracy: 0.7281 - precision: 0.7553 - recall: 0.6886 - f1: 0.7204 - val_loss: 0.6380 - val_categorical_accuracy: 0.7230 - val_precision: 0.7455 - val_recall: 0.6912 - val_f1: 0.7167\n",
            "Epoch 10/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.6067 - categorical_accuracy: 0.7320 - precision: 0.7608 - recall: 0.6920 - f1: 0.7248 - val_loss: 0.6355 - val_categorical_accuracy: 0.7217 - val_precision: 0.7461 - val_recall: 0.6862 - val_f1: 0.7110\n",
            "Epoch 11/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.5888 - categorical_accuracy: 0.7423 - precision: 0.7680 - recall: 0.7046 - f1: 0.7350 - val_loss: 0.6321 - val_categorical_accuracy: 0.7242 - val_precision: 0.7484 - val_recall: 0.6910 - val_f1: 0.7179\n",
            "Epoch 12/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.5797 - categorical_accuracy: 0.7473 - precision: 0.7712 - recall: 0.7107 - f1: 0.7397 - val_loss: 0.6322 - val_categorical_accuracy: 0.7256 - val_precision: 0.7482 - val_recall: 0.6876 - val_f1: 0.7148\n",
            "Epoch 13/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.5782 - categorical_accuracy: 0.7470 - precision: 0.7706 - recall: 0.7118 - f1: 0.7400 - val_loss: 0.6277 - val_categorical_accuracy: 0.7258 - val_precision: 0.7488 - val_recall: 0.6958 - val_f1: 0.7210\n",
            "Epoch 14/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.5643 - categorical_accuracy: 0.7531 - precision: 0.7760 - recall: 0.7206 - f1: 0.7473 - val_loss: 0.6321 - val_categorical_accuracy: 0.7301 - val_precision: 0.7499 - val_recall: 0.7057 - val_f1: 0.7271\n",
            "Epoch 15/20\n",
            "28/28 [==============================] - 43s 2s/step - loss: 0.5538 - categorical_accuracy: 0.7598 - precision: 0.7804 - recall: 0.7281 - f1: 0.7533 - val_loss: 0.6315 - val_categorical_accuracy: 0.7272 - val_precision: 0.7474 - val_recall: 0.7050 - val_f1: 0.7261\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8kiiExhcn4UA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "223034ad-ee22-4681-bfa9-aee7c806ea30"
      },
      "source": [
        "best_indiv"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7284016013145447"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w5eBHJCEo4l"
      },
      "source": [
        "train_predictions_flat_CNN = []\r\n",
        "test_predictions_flat_CNN = []\r\n",
        "\r\n",
        "for model in models:\r\n",
        "  train_predictions_flat_CNN.append(model.predict([X_train], batch_size=1024))\r\n",
        "  test_predictions_flat_CNN.append(model.predict([X_dev], batch_size=1024))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0CMagrBXEf-K"
      },
      "source": [
        "ndarray = np.array(train_predictions_flat_CNN)\r\n",
        "positive = ndarray[:,:,0]\r\n",
        "neutral = ndarray[:,:,1]\r\n",
        "negative = ndarray[:,:,2]\r\n",
        "\r\n",
        "average = (np.corrcoef(positive) + np.corrcoef(neutral) + np.corrcoef(negative))/3\r\n",
        "average"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaOKb0siEhAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "outputId": "57db1df6-9346-4edd-8e6b-7a7edbfa2158"
      },
      "source": [
        "import seaborn as sns\r\n",
        "\r\n",
        "sns.set_theme(style=\"white\")\r\n",
        "\r\n",
        "mask = np.triu(np.ones_like(average, dtype=bool))\r\n",
        "\r\n",
        "f, ax = plt.subplots(figsize=(11,9))\r\n",
        "\r\n",
        "cmap = sns.diverging_palette(220,20, n=9, as_cmap=True)\r\n",
        "\r\n",
        "sns.heatmap(average, mask=mask, cmap=cmap, vmax=1, vmin=.75, center=.9,\r\n",
        "            square=True, linewidth=.5, cbar_kws={\"shrink\":.5})"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f14021df828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 0
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 792x648 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}